{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary Data Loading and Cleaning\n",
    "After running this file, run 'Feature_Engineering.ipynb' before fitting the vectorizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id keyword location                                               text\n",
      "0   0     NaN      NaN                 Just happened a terrible car crash\n",
      "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
      "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
      "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
      "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan\n"
     ]
    }
   ],
   "source": [
    "# Load in Kaggle datasets from https://www.kaggle.com/competitions/nlp-getting-started/data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import hstack\n",
    "from joblib import dump, load\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "train = pd.read_csv(\"./Data/train.csv\")\n",
    "test = pd.read_csv(\"./Data/test.csv\")\n",
    "sample_submission = pd.read_csv(\"./Data/sample_submission.csv\")\n",
    "\n",
    "print(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = train.reset_index(drop=True)\n",
    "test_data = test.reset_index(drop=True)\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "To better understand the structure of our data before vectorizing, we will do a basic analysis to check for null values and duplicates. We will start by analyzing the null values in the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations in train data:\n",
      " 7613\n",
      "NaN counts per column in training data:\n",
      " id             0\n",
      "keyword       61\n",
      "location    2533\n",
      "text           0\n",
      "target         0\n",
      "dtype: int64\n",
      "Percentage of missing values for 'location' in training data: 33.27%\n",
      "Percentage of missing values for 'keyword' in training data: 0.80%\n"
     ]
    }
   ],
   "source": [
    "# Find length of train data\n",
    "length_train = len(train_data)\n",
    "print(\"Observations in train data:\\n\", length_train)\n",
    "\n",
    "# Check for NA values in the training dataset\n",
    "nan_counts_column_train = train_data.isna().sum()\n",
    "print(\"NaN counts per column in training data:\\n\", nan_counts_column_train)\n",
    "\n",
    "# What percentage of the observations have missing values for location?\n",
    "location_null_percentage_train = (nan_counts_column_train['location'] / len(train_data)) * 100\n",
    "print(f\"Percentage of missing values for 'location' in training data: {location_null_percentage_train:.2f}%\")\n",
    "\n",
    "# What percentage of the observations have missing values for keyword?\n",
    "location_null_percentage_train = (nan_counts_column_train['keyword'] / len(train_data)) * 100\n",
    "print(f\"Percentage of missing values for 'keyword' in training data: {location_null_percentage_train:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will find the missing values in the testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations in test data:\n",
      " 3263\n",
      "NaN counts per column in test data:\n",
      " id             0\n",
      "keyword       26\n",
      "location    1105\n",
      "text           0\n",
      "dtype: int64\n",
      "Percentage of missing values for 'location' in test dataset: 33.86%\n",
      "Percentage of missing values for 'keyword' in test dataset: 0.80%\n"
     ]
    }
   ],
   "source": [
    "# Find length of test data\n",
    "length_test = len(test_data)\n",
    "print(\"Observations in test data:\\n\", length_test)\n",
    "\n",
    "# Check for NA values in the training dataset\n",
    "nan_counts_column_test = test_data.isna().sum()\n",
    "print(\"NaN counts per column in test data:\\n\", nan_counts_column_test)\n",
    "\n",
    "# What percentage of the observations have missing values for location?\n",
    "location_null_percentage_test = (nan_counts_column_test['location'] / length_test) * 100\n",
    "print(f\"Percentage of missing values for 'location' in test dataset: {location_null_percentage_test:.2f}%\")\n",
    "\n",
    "# What percentage of the observations have missing values for keyword?\n",
    "location_null_percentage_test = (nan_counts_column_test['keyword'] / length_test) * 100\n",
    "print(f\"Percentage of missing values for 'keyword' in test dataset: {location_null_percentage_test:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code checks for duplicated rows in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Empty DataFrame\n",
      "Columns: [id, keyword, location, text, target]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicated observations in the training data\n",
    "duplicates = (train_data.duplicated())\n",
    "\n",
    "# How mant observations are duplicates?\n",
    "print(np.count_nonzero(train_data.duplicated()))\n",
    "\n",
    "# Sanity check: show all duplicated rows\n",
    "print(train_data[duplicates])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code chunk checks for duplicated rows in the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Empty DataFrame\n",
      "Columns: [id, keyword, location, text]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicated observations in the test data\n",
    "duplicates = (test_data.duplicated())\n",
    "\n",
    "# How mant observations are duplicates?\n",
    "print(np.count_nonzero(test_data.duplicated()))\n",
    "\n",
    "# Sanity check: show all duplicated rows\n",
    "print(test_data[duplicates])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, impute the missing values in the location column of the training and testing datasets with the word \"missing\" for consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute missing values using the placeholder \"missing\"\n",
    "clean_train = train_data.fillna(\"missing\")\n",
    "clean_test = test_data.fillna(\"missing\")\n",
    "\n",
    "clean_train.head()\n",
    "\n",
    "# Save clean train and test data as objects (pickle files)\n",
    "clean_train.to_pickle(\"clean_train.pkl\")\n",
    "clean_test.to_pickle(\"clean_test.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
