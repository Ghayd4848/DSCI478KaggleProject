{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id keyword location                                               text\n",
      "0   0     NaN      NaN                 Just happened a terrible car crash\n",
      "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
      "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
      "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
      "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan\n"
     ]
    }
   ],
   "source": [
    "# Load in Kaggle datasets from https://www.kaggle.com/competitions/nlp-getting-started/data\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from scipy.sparse import hstack\n",
    "from joblib import dump, load\n",
    "\n",
    "train = pd.read_csv(\"./Data/train.csv\")\n",
    "test = pd.read_csv(\"./Data/test.csv\")\n",
    "sample_submission = pd.read_csv(\"./Data/sample_submission.csv\")\n",
    "\n",
    "print(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = train.reset_index(drop=True)\n",
    "test_data = test.reset_index(drop=True)\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "To better understand the structure of our data before vectorizing, we will do a basic analysis to check for null values and duplicates. We will start by analyzing the null values in the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations in train data:\n",
      " 7613\n",
      "NaN counts per column in training data:\n",
      " id             0\n",
      "keyword       61\n",
      "location    2533\n",
      "text           0\n",
      "target         0\n",
      "dtype: int64\n",
      "Percentage of missing values for 'location' in training data: 33.27%\n",
      "Percentage of missing values for 'keyword' in training data: 0.80%\n"
     ]
    }
   ],
   "source": [
    "# Find length of train data\n",
    "length_train = len(train_data)\n",
    "print(\"Observations in train data:\\n\", length_train)\n",
    "\n",
    "# Check for NA values in the training dataset\n",
    "nan_counts_column_train = train_data.isna().sum()\n",
    "print(\"NaN counts per column in training data:\\n\", nan_counts_column_train)\n",
    "\n",
    "# What percentage of the observations have missing values for location?\n",
    "location_null_percentage_train = (nan_counts_column_train['location'] / len(train_data)) * 100\n",
    "print(f\"Percentage of missing values for 'location' in training data: {location_null_percentage_train:.2f}%\")\n",
    "\n",
    "# What percentage of the observations have missing values for keyword?\n",
    "location_null_percentage_train = (nan_counts_column_train['keyword'] / len(train_data)) * 100\n",
    "print(f\"Percentage of missing values for 'keyword' in training data: {location_null_percentage_train:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will find the missing values in the testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations in test data:\n",
      " 3263\n",
      "NaN counts per column in test data:\n",
      " id             0\n",
      "keyword       26\n",
      "location    1105\n",
      "text           0\n",
      "dtype: int64\n",
      "Percentage of missing values for 'location' in test dataset: 33.86%\n",
      "Percentage of missing values for 'keyword' in test dataset: 0.80%\n"
     ]
    }
   ],
   "source": [
    "# Find length of test data\n",
    "length_test = len(test_data)\n",
    "print(\"Observations in test data:\\n\", length_test)\n",
    "\n",
    "# Check for NA values in the training dataset\n",
    "nan_counts_column_test = test_data.isna().sum()\n",
    "print(\"NaN counts per column in test data:\\n\", nan_counts_column_test)\n",
    "\n",
    "# What percentage of the observations have missing values for location?\n",
    "location_null_percentage_test = (nan_counts_column_test['location'] / length_test) * 100\n",
    "print(f\"Percentage of missing values for 'location' in test dataset: {location_null_percentage_test:.2f}%\")\n",
    "\n",
    "# What percentage of the observations have missing values for keyword?\n",
    "location_null_percentage_test = (nan_counts_column_test['keyword'] / length_test) * 100\n",
    "print(f\"Percentage of missing values for 'keyword' in test dataset: {location_null_percentage_test:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code checks for duplicated rows in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Empty DataFrame\n",
      "Columns: [id, keyword, location, text, target]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicated observations in the training data\n",
    "duplicates = (train_data.duplicated())\n",
    "\n",
    "# How mant observations are duplicates?\n",
    "print(np.count_nonzero(train_data.duplicated()))\n",
    "\n",
    "# Sanity check: show all duplicated rows\n",
    "print(train_data[duplicates])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code chunk checks for duplicated rows in the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Empty DataFrame\n",
      "Columns: [id, keyword, location, text]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicated observations in the test data\n",
    "duplicates = (test_data.duplicated())\n",
    "\n",
    "# How mant observations are duplicates?\n",
    "print(np.count_nonzero(test_data.duplicated()))\n",
    "\n",
    "# Sanity check: show all duplicated rows\n",
    "print(test_data[duplicates])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of the smalll percentage of 'keyword' values which are missing, we will drop those observations from our testing and training datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape after removing null 'keyword': (7552, 5)\n",
      "Testing data shape after removing null 'keyword': (3237, 4)\n"
     ]
    }
   ],
   "source": [
    "# Remove rows with null values in the 'keyword' column in both training and testing datasets\n",
    "train_data = train_data.dropna(subset=['keyword'])\n",
    "test_data = test_data.dropna(subset=['keyword'])\n",
    "\n",
    "# Verify the number of rows after removal\n",
    "print(f\"Training data shape after removing null 'keyword': {train_data.shape}\")\n",
    "print(f\"Testing data shape after removing null 'keyword': {test_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, impute the missing values in the location column of the training and testing datasets with the word \"missing\" for consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>48</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>@bbcmtd Wholesale Markets ablaze http://t.co/l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>49</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Est. September 2012 - Bristol</td>\n",
       "      <td>We always try to bring the heavy. #metal #RT h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>50</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>AFRICA</td>\n",
       "      <td>#AFRICANBAZE: Breaking news:Nigeria flag set a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>52</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Philadelphia, PA</td>\n",
       "      <td>Crying out for more! Set me ablaze</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>53</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>London, UK</td>\n",
       "      <td>On plus side LOOK AT THE SKY LAST NIGHT IT WAS...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id keyword                       location  \\\n",
       "31  48  ablaze                     Birmingham   \n",
       "32  49  ablaze  Est. September 2012 - Bristol   \n",
       "33  50  ablaze                         AFRICA   \n",
       "34  52  ablaze               Philadelphia, PA   \n",
       "35  53  ablaze                     London, UK   \n",
       "\n",
       "                                                 text  target  \n",
       "31  @bbcmtd Wholesale Markets ablaze http://t.co/l...       1  \n",
       "32  We always try to bring the heavy. #metal #RT h...       0  \n",
       "33  #AFRICANBAZE: Breaking news:Nigeria flag set a...       1  \n",
       "34                 Crying out for more! Set me ablaze       0  \n",
       "35  On plus side LOOK AT THE SKY LAST NIGHT IT WAS...       0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# impute missing values using the placeholder \"missing\"\n",
    "clean_train = train_data.fillna(\"missing\")\n",
    "clean_test = test_data.fillna(\"missing\")\n",
    "\n",
    "clean_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply TD-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of combined feature matrix: (7552, 23168)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['y_train_tfidf.joblib']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the TfidfVectorizer for text columns\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# Combine the columns containing text into one before applying TD-IDF Vectorizer\n",
    "data_combined = clean_train[['keyword', 'location', 'text']].agg(' '.join, axis=1)\n",
    "\n",
    "# Vectorize 'keyword', 'location', and 'text' columns for training data\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(data_combined)\n",
    "\n",
    "# Target variable (assuming 'target' column is the label for classification)\n",
    "y_train_tfidf = clean_train['target']\n",
    "\n",
    "# Check the shape of the resulting feature matrix\n",
    "print(f\"Shape of combined feature matrix: {X_train_tfidf.shape}\")\n",
    "\n",
    "# Save the TF-IDF vectorizer and feature matrix\n",
    "dump(X_train_tfidf, 'X_train_tfidf.joblib')\n",
    "dump(y_train_tfidf, 'y_train_tfidf.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the same TD-IDF vectorizer as above, vectorize the text columns in the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of combined feature matrix: (3237, 23168)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['X_test_tfidf.joblib']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine the columns containing text into one before applying TD-IDF Vectorizer\n",
    "data_combined_test = clean_test[['keyword', 'location', 'text']].agg(' '.join, axis=1)\n",
    "\n",
    "# Vectorize 'keyword', 'location', and 'text' columns for test data\n",
    "X_test_tfidf = tfidf_vectorizer.transform(data_combined_test)\n",
    "\n",
    "# Check the shape of the resulting feature matrix\n",
    "print(f\"Shape of combined feature matrix: {X_test_tfidf.shape}\")\n",
    "\n",
    "# Save the TF-IDF vectorizer and feature matrix\n",
    "dump(tfidf_vectorizer, 'tfidf_vectorizer.joblib')\n",
    "dump(X_test_tfidf, 'X_test_tfidf.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of combined feature matrix: (7552, 23168)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['y_train_count.joblib']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Initialize the CountVectorizer for text columns\n",
    "count_vectorizer = CountVectorizer(stop_words='english')\n",
    "\n",
    "# Combine the columns containing text into one before applying CountVectorizer\n",
    "data_combined = clean_train[['keyword', 'location', 'text']].agg(' '.join, axis=1)\n",
    "\n",
    "# Vectorize 'keyword', 'location', and 'text' columns for training data\n",
    "X_train_count = count_vectorizer.fit_transform(data_combined)\n",
    "\n",
    "# Target variable (assuming 'target' column is the label for classification)\n",
    "y_train_count = clean_train['target']\n",
    "\n",
    "# Check the shape of the resulting feature matrix\n",
    "print(f\"Shape of combined feature matrix: {X_train_count.shape}\")\n",
    "\n",
    "# Save the TF-IDF vectorizer and feature matrix\n",
    "dump(X_train_count, 'X_train_count.joblib')\n",
    "dump(y_train_count, 'y_train_count.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of combined feature matrix: (3237, 23168)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['X_test_count.joblib']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine the columns containing text into one before applying TD-IDF Vectorizer\n",
    "data_combined_test = clean_test[['keyword', 'location', 'text']].agg(' '.join, axis=1)\n",
    "\n",
    "# Vectorize 'keyword', 'location', and 'text' columns for test data\n",
    "X_test_count = count_vectorizer.transform(data_combined_test)\n",
    "\n",
    "# Check the shape of the resulting feature matrix\n",
    "print(f\"Shape of combined feature matrix: {X_test_count.shape}\")\n",
    "\n",
    "# Save the TF-IDF vectorizer and feature matrix\n",
    "dump(count_vectorizer, 'count_vectorizer.joblib')\n",
    "dump(X_test_count, 'X_test_count.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
