{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of a Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from pickle import load\n",
    "from joblib import load\n",
    "\n",
    "# Load in the target once, which can be used for both vectorizers\n",
    "with open('target.pkl', 'rb') as f:\n",
    "    target = load(f)\n",
    "\n",
    "# Load the saved TF-IDF feature matrix and target variable for the training data\n",
    "with open('model_train_tfidf.pkl', 'rb') as f:\n",
    "    model_train_tfidf = load(f)\n",
    "with open('model_test_tfidf.pkl', 'rb') as f:\n",
    "    model_test_tfidf = load(f)\n",
    "\n",
    "# Load the saved Count Vectorizer feature matrix and target varible for the training data\n",
    "with open('model_train_count.pkl', 'rb') as f:\n",
    "    model_train_count = load(f)\n",
    "with open('model_test_count.pkl', 'rb') as f:\n",
    "    model_test_count = load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the training data into training and validation sets\n",
    "X_validation_train_tfidf, X_validation_test_tfidf, y_validation_train_tfidf, y_validation_test_tfidf = train_test_split(model_train_tfidf, target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.68978069\n",
      "Iteration 2, loss = 0.68420567\n",
      "Iteration 3, loss = 0.68379813\n",
      "Iteration 4, loss = 0.68391965\n",
      "Iteration 5, loss = 0.68386163\n",
      "Iteration 6, loss = 0.68356385\n",
      "Iteration 7, loss = 0.68400841\n",
      "Iteration 8, loss = 0.68379394\n",
      "Iteration 9, loss = 0.68388620\n",
      "Iteration 10, loss = 0.68383690\n",
      "Iteration 11, loss = 0.68397815\n",
      "Iteration 12, loss = 0.68375729\n",
      "Iteration 13, loss = 0.68367713\n",
      "Iteration 14, loss = 0.68374642\n",
      "Iteration 15, loss = 0.68386832\n",
      "Iteration 16, loss = 0.68390531\n",
      "Iteration 17, loss = 0.68385507\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.002000\n",
      "Iteration 18, loss = 0.68365377\n",
      "Iteration 19, loss = 0.68364273\n",
      "Iteration 20, loss = 0.68363798\n",
      "Iteration 21, loss = 0.68360507\n",
      "Iteration 22, loss = 0.68361590\n",
      "Iteration 23, loss = 0.68362046\n",
      "Iteration 24, loss = 0.68363699\n",
      "Iteration 25, loss = 0.68359542\n",
      "Iteration 26, loss = 0.68361129\n",
      "Iteration 27, loss = 0.68361666\n",
      "Iteration 28, loss = 0.68360922\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000400\n",
      "Iteration 29, loss = 0.68357597\n",
      "Iteration 30, loss = 0.68356891\n",
      "Iteration 31, loss = 0.68355819\n",
      "Iteration 32, loss = 0.68356030\n",
      "Iteration 33, loss = 0.68356352\n",
      "Iteration 34, loss = 0.68356528\n",
      "Iteration 35, loss = 0.68356275\n",
      "Iteration 36, loss = 0.68356880\n",
      "Iteration 37, loss = 0.68356176\n",
      "Iteration 38, loss = 0.68356191\n",
      "Iteration 39, loss = 0.68356556\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000080\n",
      "Iteration 40, loss = 0.68355306\n",
      "Iteration 41, loss = 0.68355267\n",
      "Iteration 42, loss = 0.68355205\n",
      "Iteration 43, loss = 0.68355260\n",
      "Iteration 44, loss = 0.68355156\n",
      "Iteration 45, loss = 0.68355193\n",
      "Iteration 46, loss = 0.68355173\n",
      "Iteration 47, loss = 0.68355234\n",
      "Iteration 48, loss = 0.68355256\n",
      "Iteration 49, loss = 0.68355106\n",
      "Iteration 50, loss = 0.68355196\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000016\n",
      "F1: 0.4185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "mlp_tfidf = MLPClassifier(hidden_layer_sizes=(20,8),  # Two hidden layers, with 512 and 256 neurons respectively     \n",
    "                    solver='sgd',                 # SGD optimizer\n",
    "                    alpha = 0.0001,                # default for l2 (ridge)\n",
    "                    max_iter=50,                # Maximum number of iterations\n",
    "                    random_state=42,             # Random seed for reproducibility\n",
    "                    batch_size=32,               # Batch size for gradient descent\n",
    "                    learning_rate='adaptive',    # Adaptive learning rate\n",
    "                    learning_rate_init = 0.01,\n",
    "                    momentum = 0.9,\n",
    "                    nesterovs_momentum = True,\n",
    "                    early_stopping = False,\n",
    "                    warm_start=False,            # Whether to reuse the previous solution\n",
    "                    tol=1e-4,                    # Tolerance for stopping\n",
    "                    verbose=True)       \n",
    "\n",
    "mlp_tfidf.fit(X_validation_train_tfidf, y_validation_train_tfidf)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_val_pred_tfidf = mlp_tfidf.predict(X_validation_test_tfidf)\n",
    "\n",
    "# Evaluate the model performance (e.g., accuracy)\n",
    "from sklearn.metrics import f1_score\n",
    "f1score = f1_score(y_validation_test_tfidf, y_val_pred_tfidf, average='weighted')\n",
    "\n",
    "print(f\"F1: {f1score:.4f}\")\n",
    "\n",
    "#joblib.dump(mlp, 'mlp_model.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
